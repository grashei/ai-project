{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from math import ceil\n",
    "from typing import List\n",
    "from typing import Set\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from evaluation import MyPredictionModel\n",
    "from evaluation import evaluate_graphs\n",
    "from graph import Graph\n",
    "from mapping import Mapper, FamilyIdMapper, PartIdMapper\n",
    "from node import Node\n",
    "from part import Part\n",
    "from utils import load_graphs\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps else \"cpu\")\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "graphs = load_graphs()\n",
    "random.shuffle(graphs)\n",
    "\n",
    "\n",
    "model_fam_exists = os.path.exists(\"data/karl_fam.dat\")\n",
    "model_part_exists = os.path.exists(\"data/karl_part.dat\")\n",
    "execute_grid_search = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = [len(g.get_nodes()) for g in graphs]\n",
    "_ = plt.hist(a)  # arguments are passed to np.histogram\n",
    "plt.title(\"Graph Node Count Histogram\")\n",
    "plt.xlabel(\"#Nodes per Graph\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load graphs dataset, shuffle it and split it into training, validation and test set. We use a train, validation, test split of 80%, 10%, 10%."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "training_set_size_ratio = 0.8\n",
    "validation_set_size_ratio = 0.10\n",
    "test_size_ratio = 0.10\n",
    "\n",
    "assert training_set_size_ratio + test_size_ratio + validation_set_size_ratio == 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dense Family ID Mapping\n",
    "All parts have a family that lies between 0 and 95 (inclusive). However, some family IDs, like 16, don't appear in the dataset. We create a dense family ID mapping and use dense family IDs to shorten our model's feature vector. For example, family ID 17 is converted to dense Family ID 16 due to the gap Family ID 16 left."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "fam_mapper = FamilyIdMapper(graphs)\n",
    "\n",
    "\n",
    "def get_ofid(self):\n",
    "    \"\"\"\n",
    "    :return: the original family if of the node's part\n",
    "    \"\"\"\n",
    "    return int(self.get_family_id())\n",
    "\n",
    "\n",
    "def get_dfid(self):\n",
    "    \"\"\"\n",
    "    :return: the dense family if of the node's part\n",
    "    \"\"\"\n",
    "    return fam_mapper.to_dense(self.get_ofid())\n",
    "\n",
    "\n",
    "# Add extension functions to nodes to make code easier to read\n",
    "Part.get_ofid = get_ofid\n",
    "Part.get_dfid = get_dfid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dense Part ID Mapping\n",
    "\n",
    "We compare the predictions of the model using only the family ID against using only the part ID. Hence we setup the part ID mapping analogously."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "part_mapper = PartIdMapper(graphs)\n",
    "\n",
    "def get_opid(self):\n",
    "    \"\"\"\n",
    "    :return: the original part id of the node's part\n",
    "    \"\"\"\n",
    "    return int(self.get_part_id())\n",
    "\n",
    "\n",
    "def get_dpid(self):\n",
    "    \"\"\"\n",
    "    :return: the dense part id of the node's part\n",
    "    \"\"\"\n",
    "    return part_mapper.to_dense(self.get_opid())\n",
    "\n",
    "\n",
    "# Add extension functions to nodes to make code easier to read\n",
    "Part.get_opid = get_opid\n",
    "Part.get_dpid = get_dpid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Hyperparameters\n",
    "\n",
    "For initially comparing the two models we set the hyperparameters as following. We do hyperparameter optimization later as we determined the better alternative between using only family IDs or only part IDs as features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "input_size_fam = 2 * len(fam_mapper)  # 184\n",
    "hidden_size_fam = 2 * input_size_fam # 368\n",
    "output_size_fam = len(fam_mapper)  # 92\n",
    "\n",
    "input_size_part = 2 * len(part_mapper)  # 2162\n",
    "hidden_size_part = 2 * input_size_part # 4324\n",
    "output_size_part = len(part_mapper)  # 1081\n",
    "\n",
    "\n",
    "learning_rate = 0.003\n",
    "num_epochs = 50"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Our Model KantenKennerKarl\n",
    "\n",
    "We decided to use a feedforward neural network, because we have to deal with high dimensional categorical data. It is a simple feedforward neural network consisting of just two hidden layers. This makes it extremely efficient. The model does not directly predict the edges for a set of parts. Instead, it predicts all the neighbors of one node of a Graph. This means it performs multiclass classification, and we need sigmoid as activation function for the output layer to predict scores for multiple classes. Because we have categorical data we also dont normalize the data first."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 2 * hidden_size)\n",
    "        self.fc2 = nn.Linear(2 * hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Features\n",
    "\n",
    "The model takes a 1D tensor that can be divided into two parts `all_nodes_tensor` (first half) and `given_node_tensor` (second half):\n",
    "- `all_nodes_tensor`: one-hot encoded dense family IDs for each part that we should use to build the graph. E.g., (1,0,3,0,...,0) means that the graph consists of one part with dense family ID 0 and three parts with dense family ID 2.\n",
    "- `given_node_tensor`: one-hot encoded dense family ID for which the model should predict its neighbors. E.g., (0,0,1,0,...,0) means that the model should predict the neighbors of all parts with dense family id 2.\n",
    "\n",
    "We do the same analogously for the approach using only the part IDs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_features_family_id(parts: Set[Part], fam_mapping: FamilyIdMapper) -> List[Tensor]:\n",
    "    parts_sorted = list(parts)\n",
    "    parts_sorted.sort()\n",
    "\n",
    "    num_different_family_ids = len(fam_mapping)\n",
    "\n",
    "    all_nodes_tensor = torch.zeros(num_different_family_ids, dtype=torch.float)\n",
    "\n",
    "    for part in parts_sorted:\n",
    "        dense_family_id = part.get_dfid()\n",
    "        all_nodes_tensor[dense_family_id] += 1.0\n",
    "\n",
    "    feature_tensors = []\n",
    "\n",
    "    for part in parts_sorted:\n",
    "        dense_family_id = part.get_dfid()\n",
    "        given_node_tensor = torch.zeros(num_different_family_ids, dtype=torch.float)\n",
    "        given_node_tensor[dense_family_id] = 1\n",
    "        feature_tensor = torch.cat((all_nodes_tensor, given_node_tensor), dim=-1)\n",
    "        feature_tensors.append(feature_tensor)\n",
    "\n",
    "    return feature_tensors\n",
    "\n",
    "def create_features_part_id(parts: Set[Part], part_mapper: PartIdMapper) -> List[Tensor]:\n",
    "    parts_sorted = list(parts)\n",
    "    parts_sorted.sort()\n",
    "\n",
    "    num_different_part_ids = len(part_mapper)\n",
    "\n",
    "    all_nodes_tensor = torch.zeros(num_different_part_ids, dtype=torch.float)\n",
    "\n",
    "    for part in parts_sorted:\n",
    "        dense_part_id = part.get_dpid()\n",
    "        all_nodes_tensor[dense_part_id] += 1.0\n",
    "\n",
    "    feature_tensors = []\n",
    "\n",
    "    for part in parts_sorted:\n",
    "        dense_part_id = part.get_dpid()\n",
    "        given_node_tensor = torch.zeros(num_different_part_ids, dtype=torch.float)\n",
    "        given_node_tensor[dense_part_id] = 1\n",
    "        feature_tensor = torch.cat((all_nodes_tensor, given_node_tensor), dim=-1)\n",
    "        feature_tensors.append(feature_tensor)\n",
    "\n",
    "    return feature_tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Labels\n",
    "\n",
    "The model outputs a 1D tensor that represents the neighbors of a given node. E.g., (1,0,1,0,...,0) means that the given node (only) has two neighbors: one with dense family ID 0 and one with dense family ID 2. Analogously for the part IDs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def create_labels_family_id(graph: Graph, fam_mapping: FamilyIdMapper) -> List[Tensor]:\n",
    "    \"\"\"\n",
    "    Creates the ground truth tensors for a given graph in one hot encoded form by using the family ids\n",
    "    :param graph: The graph for which the tensors should be created\n",
    "    :param fam_mapping: The mapper for the family ids\n",
    "    :return: The list containing all ground truth tensors for the graph\n",
    "    \"\"\"\n",
    "    label_tensors = []\n",
    "\n",
    "    num_different_family_ids = len(fam_mapping)\n",
    "    edges = graph.get_edges()\n",
    "\n",
    "    for node in sorted(graph.get_nodes()):\n",
    "        target_tensor = torch.zeros(num_different_family_ids, dtype=torch.float)\n",
    "        for neighbour_node in edges[node]:\n",
    "            neighbour_node_dense_family_id = neighbour_node.get_part().get_dfid()\n",
    "            target_tensor[neighbour_node_dense_family_id] = 1\n",
    "        label_tensors.append(target_tensor)\n",
    "    return label_tensors\n",
    "\n",
    "\n",
    "def create_labels_part_id(graph: Graph, part_mapping: PartIdMapper) -> List[Tensor]:\n",
    "    \"\"\"\n",
    "    Creates the ground truth tensors for a given graph in one hot encoded form by using the part ids\n",
    "    :param graph: The graph for which the tensors should be created\n",
    "    :param part_mapping: The mapper for the part ids\n",
    "    :return: The list containing all ground truth tensors for the graph\n",
    "    \"\"\"\n",
    "    label_tensors = []\n",
    "\n",
    "    num_different_part_ids = len(part_mapping)\n",
    "    edges = graph.get_edges()\n",
    "\n",
    "    for node in sorted(graph.get_nodes()):\n",
    "        target_tensor = torch.zeros(num_different_part_ids, dtype=torch.float)\n",
    "        for neighbour_node in edges[node]:\n",
    "            neighbour_node_dense_part_id = neighbour_node.get_part().get_dpid()\n",
    "            target_tensor[neighbour_node_dense_part_id] = 1\n",
    "        label_tensors.append(target_tensor)\n",
    "    return label_tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train, validation and test split\n",
    "\n",
    "We split the dataset into train, val and test sets. The hyperparameters are only tuned on the validation dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_upper = ceil(training_set_size_ratio * len(graphs))\n",
    "val_upper = ceil((training_set_size_ratio + validation_set_size_ratio) * len(graphs))\n",
    "\n",
    "train_graphs = graphs[0:train_upper]\n",
    "val_graphs = graphs[train_upper:val_upper]\n",
    "test_graphs = graphs[val_upper:len(graphs) + 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset & Dataloader\n",
    "\n",
    "In order to simplify training with PyTorch we create a dataset containing the input features and target labels based on the family id. During training we shuffle the dataset to prevent overfitting. We use the mini-batch variant for gradient descent because it speeds up training but has also a smooth trajectory regarding the loss curve later."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def create_features_and_labels_family_id(graph: Graph, fam_mapping: FamilyIdMapper) -> Tuple[List[Tensor], List[Tensor]]:\n",
    "    feature_tensors = create_features_family_id(graph.get_parts(), fam_mapping)\n",
    "    label_tensors = create_labels_family_id(graph, fam_mapping)\n",
    "    return feature_tensors, label_tensors\n",
    "\n",
    "class GraphDatasetFamilyId(Dataset):\n",
    "    def __init__(self, graphs: List[Graph]):\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        for graph in graphs:\n",
    "            x_per_graph, y_per_graph = create_features_and_labels_family_id(graph, fam_mapper)\n",
    "            x_list += x_per_graph\n",
    "            y_list += y_per_graph\n",
    "        self.x_tensor = torch.stack(x_list)\n",
    "        self.y_tensor = torch.stack(y_list)\n",
    "        self.n_samples = self.y_tensor.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_tensor[index], self.y_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "train_loader_fam_id = DataLoader(\n",
    "    dataset=GraphDatasetFamilyId(train_graphs),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader_fam_id = DataLoader(\n",
    "    dataset=GraphDatasetFamilyId(val_graphs),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do the same for our features using only the part id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def create_features_and_labels_part_id(graph: Graph, part_mapping: PartIdMapper) -> Tuple[List[Tensor], List[Tensor]]:\n",
    "    feature_tensors = create_features_part_id(graph.get_parts(), part_mapping)\n",
    "    label_tensors = create_labels_part_id(graph, part_mapping)\n",
    "    return feature_tensors, label_tensors\n",
    "\n",
    "class GraphDatasetPartId(Dataset):\n",
    "    def __init__(self, graphs: List[Graph]):\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        for graph in graphs:\n",
    "            x_per_graph, y_per_graph = create_features_and_labels_part_id(graph, part_mapper)\n",
    "            x_list += x_per_graph\n",
    "            y_list += y_per_graph\n",
    "        self.x_tensor = torch.stack(x_list)\n",
    "        self.y_tensor = torch.stack(y_list)\n",
    "        self.n_samples = self.y_tensor.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_tensor[index], self.y_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "train_loader_part_id = DataLoader(\n",
    "    dataset=GraphDatasetPartId(train_graphs),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader_part_id = DataLoader(\n",
    "    dataset=GraphDatasetPartId(val_graphs),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training routine\n",
    "\n",
    "Our training routing trains the given model with the given learning rate for the number of specified epochs. After each epoch it validates the current state of the model on the validation dataset. The stats for the loss and accuracy are tracked and is used for hyperparameter optimization and recognizing over- or underfitting of the model. We use Binary Cross Entropy as loss function because we deal with categorical data. As optimizer we use Adam because it gave us the best results in earlier experiments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train(model, lr, epochs, train_loader, val_loader, show_progress=True):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for _ in tqdm(range(epochs), ascii=\"░▒█\", disable=not show_progress):\n",
    "        train_losses_per_epoch = 0.0\n",
    "        train_accuracy_per_epoch = 0.0\n",
    "        for i, (x_train, y_train) in enumerate(train_loader):\n",
    "            x_train = x_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            y_pred = model(x_train)\n",
    "            loss = loss_fn(y_pred, y_train)\n",
    "            train_losses_per_epoch += loss.cpu().detach().numpy()\n",
    "            train_accuracy = torch.sum(y_train == y_pred.round()) / torch.numel(y_train)\n",
    "            train_accuracy_per_epoch += train_accuracy.cpu().detach().numpy()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_losses.append(train_losses_per_epoch / len(train_loader_fam_id))\n",
    "        train_accuracies.append(train_accuracy_per_epoch / len(train_loader_fam_id))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_losses_per_epoch = 0.0\n",
    "            val_accuracies_per_epoch = 0.0\n",
    "            for i, (x_val, y_val) in enumerate(val_loader):\n",
    "                x_val = x_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                y_pred = model(x_val)\n",
    "                loss = loss_fn(y_pred, y_val)\n",
    "                val_accuracy = torch.sum(y_val == y_pred.round()) / torch.numel(y_val)\n",
    "                val_losses_per_epoch += loss.cpu()\n",
    "                val_accuracies_per_epoch += val_accuracy.cpu()\n",
    "            val_losses.append(val_losses_per_epoch / len(val_loader_fam_id))\n",
    "            val_accuracies.append(val_accuracies_per_epoch / len(val_loader_fam_id))\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training with family IDs\n",
    "\n",
    "First, our model is trained using only the family IDs. The time to train the model is measured and printed afterwards. Afterwards plot the resulting graphs of the training with family IDs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "percentage_formatter = FuncFormatter(lambda y, _: '{:.2%}'.format(y))\n",
    "\n",
    "if not model_fam_exists:\n",
    "    model_karl_fam_id = Net(input_size=input_size_fam, hidden_size=hidden_size_fam, output_size=output_size_fam).to(device)\n",
    "\n",
    "    st = time.time()\n",
    "    train_losses_fam, val_losses_fam, train_accuracies_fam, val_accuracies_fam =\\\n",
    "        train(model=model_karl_fam_id, lr=learning_rate, epochs=num_epochs, train_loader=train_loader_fam_id, val_loader=val_loader_fam_id)\n",
    "\n",
    "    et = time.time()\n",
    "    print(f\"Execution time: {(et - st):.2f} seconds\")\n",
    "    torch.save(model_karl_fam_id, \"data/karl_fam.dat\")\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 4))\n",
    "\n",
    "    ax1.set(xlabel='#Epochs', ylabel='Loss')\n",
    "    fig.suptitle('Learning Progress')\n",
    "    ax1.plot(train_losses_fam, label=\"Training Loss\")\n",
    "    ax1.plot(val_losses_fam, label=\"Validation Loss\")\n",
    "    ax1.yaxis.set_major_formatter(percentage_formatter)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set(xlabel='#Epochs', ylabel='Accuracy')\n",
    "    ax2.plot(train_accuracies_fam, label=\"Train Accuracy\")\n",
    "    ax2.plot(val_accuracies_fam, label=\"Validation Accuracy\")\n",
    "    ax2.yaxis.set_major_formatter(percentage_formatter)\n",
    "    ax2.legend()\n",
    "\n",
    "    real_validation_errors = [1.0 - (train_accuracy + abs(val_accuracy - train_accuracy)) for train_accuracy, val_accuracy in zip(train_accuracies_fam,val_accuracies_fam)]\n",
    "    ax3.set(xlabel='#Epochs', ylabel='Real Val Error (e_train + |e_val - e_train|)')\n",
    "    ax3.plot(real_validation_errors)\n",
    "    ax3.yaxis.set_major_formatter(percentage_formatter)\n",
    "else:\n",
    "    model_karl_fam_id = torch.load(\"data/karl_fam.dat\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the model's accuracy against the validation set is already higher than 99.9% and doesn't show signs of overfitting, we see little potential in optimizing it further and kept Karl relatively simple. Also we decided to not use any regularization on our model, because the performance on the validation set is almost the same as for the traning set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Some helper methods for prediction of graphs\n",
    "\n",
    "def check_for_cycle(graph: Graph, source: Part, sink: Part):\n",
    "    graph.add_undirected_edge(source, sink)\n",
    "    return graph.is_cyclic()\n",
    "\n",
    "def get_parts_with_fam_id(parts: List[Part], fam_id: int) -> List[Part]:\n",
    "    return [part for part in parts if part.get_ofid() == fam_id]\n",
    "\n",
    "\n",
    "def get_least_fam_id_neighbours_node(graph: Graph, nodes: List[Node], fam_id: int) -> Node:\n",
    "    balance_counts = [0] * len(nodes)\n",
    "    for i, node in enumerate(nodes):\n",
    "        edges = graph.get_edges().get(node)\n",
    "        if edges is not None:\n",
    "            balance_counts[i] = \\\n",
    "                sum(1 if n.get_ofid() == fam_id else 0 for n in edges)\n",
    "\n",
    "    balanced_node_idx: int = np.array(balance_counts).argmin()\n",
    "    node = nodes[balanced_node_idx]\n",
    "    return node"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1116/1116 [00:57<00:00, 19.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean edge accuracy: 98.66378354402306\n",
      "Execution time: 57.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class GraphenGuruGuenterFamId(MyPredictionModel):\n",
    "\n",
    "    def __init__(self, model, fam_mapping):\n",
    "        self.model = model\n",
    "        self.fam_mapping = fam_mapping\n",
    "\n",
    "    def predict_graph(self, parts: Set[Part]) -> Graph:\n",
    "        raw_predictions = []\n",
    "        feature_tensors = create_features_family_id(parts, self.fam_mapping)\n",
    "        for feature_tensor in feature_tensors:\n",
    "            prediction = self.model(feature_tensor)\n",
    "            raw_predictions.append(prediction)\n",
    "        raw_predictions = torch.stack(raw_predictions)\n",
    "        return self.build_predicted_graph(parts, raw_predictions)\n",
    "\n",
    "    def build_predicted_graph(self, parts: Set[Part], pred_adj_matrix: Tensor) -> Graph:\n",
    "        parts_list = sorted(list(parts))\n",
    "        added_parts = set()\n",
    "        node_count = len(parts_list)\n",
    "        predicted_graph = Graph()\n",
    "        parts_at_nodes = dict()\n",
    "        for p in parts:\n",
    "            parts_at_nodes[p] = []\n",
    "\n",
    "        while predicted_graph.get_edge_count() // 2 < node_count - 1 and not torch.all(pred_adj_matrix < 1e-3):\n",
    "            max_signal_idx = (pred_adj_matrix == torch.max(pred_adj_matrix)).nonzero()\n",
    "            source_idx = max_signal_idx[0][0].item()\n",
    "            sink_dense_fam_id = max_signal_idx[0][1].item()\n",
    "\n",
    "            source_orig_fam_id = parts_list[source_idx].get_ofid()\n",
    "            sink_orig_fam_id = self.fam_mapping.to_orig(sink_dense_fam_id)\n",
    "            source = parts_list[source_idx]\n",
    "\n",
    "            parts_with_sink_fam_id = get_parts_with_fam_id(parts_list, sink_orig_fam_id)\n",
    "            parts_with_sink_fam_id = sorted(parts_with_sink_fam_id, key=lambda x: parts_at_nodes[x].count(source_orig_fam_id))\n",
    "\n",
    "            for sink in parts_with_sink_fam_id:\n",
    "                if (source != sink and not (source in added_parts and sink in added_parts)) or not predicted_graph.is_reachable(source, sink):\n",
    "                    parts_at_nodes[source] += [sink_orig_fam_id]\n",
    "                    parts_at_nodes[sink] += [source_orig_fam_id]\n",
    "                    predicted_graph.add_undirected_edge(source, sink)\n",
    "                    added_parts.add(source)\n",
    "                    added_parts.add(sink)\n",
    "                    break\n",
    "\n",
    "\n",
    "            pred_adj_matrix[source_idx][sink_dense_fam_id] = 0.0\n",
    "        return predicted_graph\n",
    "\n",
    "\n",
    "predictor = GraphenGuruGuenterFamId(model_karl_fam_id.cpu(), fam_mapper)\n",
    "with torch.no_grad():\n",
    "    st = time.time()\n",
    "    accuracy = evaluate_graphs(predictor, val_graphs)\n",
    "    print(f\"Mean edge accuracy: {accuracy}\")\n",
    "    et = time.time()\n",
    "    print(f\"Execution time: {(et - st):.2f}s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training with part IDs\n",
    "\n",
    "Here we perform training and evaluation of the model using only the part IDs. The model is structurally the same but has more parameters in order to handle the larger feature vectors. Afterwards plot the resulting graphs for training with part IDs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█░░░░░░░░░| 2/20 [00:29<04:25, 14.73s/it]"
     ]
    }
   ],
   "source": [
    "if not model_part_exists:\n",
    "    model_karl_part_id = Net(input_size=input_size_part, hidden_size=hidden_size_part, output_size=output_size_part).to(device)\n",
    "\n",
    "    st = time.time()\n",
    "    train_losses_part, val_losses_part, train_accuracies_part, val_accuracies_part = \\\n",
    "        train(model=model_karl_part_id, lr=learning_rate, epochs=20, train_loader=train_loader_part_id, val_loader=val_loader_part_id)\n",
    "\n",
    "    et = time.time()\n",
    "    print(f\"Execution time: {(et - st):.2f} seconds\")\n",
    "    torch.save(model_karl_part_id, \"data/karl_part.dat\")\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(20, 4))\n",
    "\n",
    "    ax1.set(xlabel='#Epochs', ylabel='Loss')\n",
    "    fig.suptitle('Learning Progress')\n",
    "    ax1.plot(train_losses_part, label=\"Training Loss\")\n",
    "    ax1.plot(val_losses_part, label=\"Validation Loss\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set(xlabel='#Epochs', ylabel='Accuracy')\n",
    "    ax2.plot(train_accuracies_part, label=\"Train Accuracy\")\n",
    "    ax2.plot(val_accuracies_part, label=\"Validation Accuracy\")\n",
    "    ax2.legend()\n",
    "    ax2.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.2%}'.format(y)))\n",
    "\n",
    "    real_validation_errors = [1.0 - (train_accuracy + abs(val_accuracy - train_accuracy)) for train_accuracy, val_accuracy in zip(train_accuracies_part,val_accuracies_part)]\n",
    "    ax3.set(xlabel='#Epochs', ylabel='Real Val Error (e_train + |e_val - e_train|)')\n",
    "    ax3.plot(real_validation_errors)\n",
    "    ax3.yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.2%}'.format(y)))\n",
    "\n",
    "else:\n",
    "    model_karl_part_id = torch.load(\"data/karl_part.dat\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Some helper methods for prediction of graphs with part IDs\n",
    "\n",
    "def get_parts_with_part_id(parts: List[Part], part_id: int) -> List[Part]:\n",
    "    return [part for part in parts if part.get_opid() == part_id]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We build the graph from the predictions using the following algorithm. We obtain the edge from the prediction matrix with the highest value and insert it into the graph. Afterwards the set the prediction value to 0 for that edge. We repeat this until the graph has n-1 edges, if n is the number of nodes. When there are multiple nodes in the graph with the same id to which the edge could be attached, we select the one with the lowest number of neighbours with the sink ID. We have discovered, that the Graphs are in parts symmetrically. By this we take this condition into account and balance the nodes more symmetrically. Moreover, our model and prediction algorithm is independent of big the graph is and can cope with any graph size."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GraphenGuruGuenterPartId(MyPredictionModel):\n",
    "\n",
    "    def __init__(self, model, part_mapping):\n",
    "        self.model = model\n",
    "        self.part_mapping = part_mapping\n",
    "\n",
    "    def predict_graph(self, parts: Set[Part]) -> Graph:\n",
    "        raw_predictions = []\n",
    "        feature_tensors = create_features_part_id(parts, self.part_mapping)\n",
    "        for feature_tensor in feature_tensors:\n",
    "            prediction = self.model(feature_tensor)\n",
    "            raw_predictions.append(prediction)\n",
    "        raw_predictions = torch.stack(raw_predictions)\n",
    "        return self.build_predicted_graph(parts, raw_predictions)\n",
    "\n",
    "    def build_predicted_graph(self, parts: Set[Part], pred_adj_matrix: Tensor) -> Graph:\n",
    "        parts_list = sorted(list(parts))\n",
    "        added_parts = set()\n",
    "        node_count = len(parts_list)\n",
    "        predicted_graph = Graph()\n",
    "        parts_at_nodes = dict()\n",
    "        for p in parts:\n",
    "            parts_at_nodes[p] = []\n",
    "\n",
    "        while predicted_graph.get_edge_count() // 2 < node_count - 1 and not torch.all(pred_adj_matrix == 0):\n",
    "\n",
    "            max_signal_idx = (pred_adj_matrix == torch.max(pred_adj_matrix)).nonzero()\n",
    "            source_idx = max_signal_idx[0][0].item()\n",
    "            sink_dense_part_id = max_signal_idx[0][1].item()\n",
    "\n",
    "            source_orig_part_id = parts_list[source_idx].get_opid()\n",
    "            sink_orig_part_id = self.part_mapping.to_orig(sink_dense_part_id)\n",
    "            source = parts_list[source_idx]\n",
    "\n",
    "            parts_with_sink_part_id = get_parts_with_part_id(parts_list, sink_orig_part_id)\n",
    "            parts_with_sink_part_id = sorted(parts_with_sink_part_id, key=lambda x: parts_at_nodes[x].count(source_orig_part_id))\n",
    "\n",
    "            for sink in parts_with_sink_part_id:\n",
    "                if source != sink and not (source in added_parts and sink in added_parts) or not predicted_graph.is_reachable(source,sink):\n",
    "                    parts_at_nodes[source] += [sink_orig_part_id]\n",
    "                    parts_at_nodes[sink] += [source_orig_part_id]\n",
    "                    predicted_graph.add_undirected_edge(source, sink)\n",
    "                    added_parts.add(source)\n",
    "                    added_parts.add(sink)\n",
    "\n",
    "            pred_adj_matrix[source_idx][sink_dense_part_id] = 0.0\n",
    "        return predicted_graph\n",
    "\n",
    "\n",
    "predictor = GraphenGuruGuenterPartId(model_karl_part_id.cpu(), part_mapper)\n",
    "\n",
    "with torch.no_grad():\n",
    "    st = time.time()\n",
    "    accuracy = evaluate_graphs(predictor, val_graphs)\n",
    "    print(f\"Mean edge accuracy: {accuracy}\")\n",
    "    et = time.time()\n",
    "    print(f\"Execution time: {(et - st):.2f}s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Family IDs or part IDs?\n",
    "\n",
    "As can be seen above, the model using only the part IDs has approximately the same performance as the model using only the family IDs. Because training and inference with the latter is much faster we stick to the approach with the family IDs from here on."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Because our model is very fast to train, we can try a lot of different hyperparameter settings. As described in the lecture we use a grid search approach here for finding the best hyperparameter setting. We will tune hidden layer size, learning rate, epochs. We intentionally skip the drawing of the loss and accuracy charts to no clutter the output due to the high number of combinations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "if execute_grid_search:\n",
    "    num_ids = len(fam_mapper)\n",
    "    hidden_layer_sizes = [1 * num_ids, 2 * num_ids]\n",
    "    learning_rates = [0.001, 0.01]\n",
    "    epochs = [10, 20, 50]\n",
    "    permutations = list(itertools.product(hidden_layer_sizes, learning_rates, epochs))\n",
    "\n",
    "    results = []\n",
    "    best_predictor = None\n",
    "    best_accuracy = 0.\n",
    "    with tqdm(permutations) as permutation_progress:\n",
    "        for layer_size, lr, epochs in permutation_progress:\n",
    "            model_karl_fam_id = Net(input_size=input_size_fam, hidden_size=layer_size, output_size=output_size_fam).to(device)\n",
    "            train(model=model_karl_fam_id, lr=lr, epochs=epochs, train_loader=train_loader_fam_id, val_loader=val_loader_fam_id, show_progress=False)\n",
    "\n",
    "            predictor = GraphenGuruGuenterFamId(model_karl_fam_id.cpu(), fam_mapper)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                accuracy = evaluate_graphs(predictor, val_graphs, show_progress=False)\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_predictor = predictor\n",
    "                results.append((layer_size, lr, epochs, accuracy))\n",
    "\n",
    "\n",
    "    results =  sorted(results, key=lambda x: x[3], reverse=True)\n",
    "    t = PrettyTable(['Hidden Layer Size', 'Learning Rate', 'Epochs', 'Accuracy'])\n",
    "    for row in results:\n",
    "        t.add_row(row)\n",
    "\n",
    "    print(t)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save prediction model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('data/predictor.dat', 'xb') as file:\n",
    "        pickle.dump(predictor, file=file)\n",
    "except FileExistsError:\n",
    "    print(\"Accidental overwrite protection: File already exists\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('data/predictor.dat', 'rb') as file:\n",
    "        test_predictor = pickle.load(file)\n",
    "    with torch.no_grad():\n",
    "        st = time.time()\n",
    "        accuracy = evaluate_graphs(test_predictor, test_graphs)\n",
    "        print(f\"Mean edge accuracy: {accuracy}\")\n",
    "        et = time.time()\n",
    "        print(f\"Execution time: {(et - st):.2f}s\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Model file not found\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
